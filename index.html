<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0090)file:///E:/WCXIE/Websites/simple-one/Amelie%20Chi%20Zhou%20@%20Shenzhen%20University.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="Keywords" content="Weicheng Xie, facial expression analysis, deep metric learning">

<meta name="Distribution" content="Weicheng Xie's Homepage">
<meta name="Author" content="Weicheng Xie">
<meta name="description" content="homepage">
<meta name="Robots" content="index,follow">

<link rel="stylesheet" href="./index_files/CoolWater1.css" type="text/css">

<title>Weicheng Xie's Homepage</title>
<style type="text/css">
<!--
.style26 {color: #000000}
.style46 {font-family: Calibri}
.style57 {font-family: "Century Gothic"; font-size: 120%; color: #000000;}
.style61 {font-family: "Century Gothic"}
.style64 {font-size: 130%; font-weight: bold; font-family: "Century Gothic"; }
.style81 {
	color: #333333;
	font-family: "Century Gothic";
	font-weight: bold;
}
.style84 {
	font-size: 150%;
	font-family: "Century Gothic";
	color: #000000;
}
.style86 {
	color: #3366FF;
	font-family: "Century Gothic";
	font-size: 300%;
}
.style88 {color: #3366FF; font-family: "Century Gothic"; font-size: 200%; }
.style89 {
	color: #3366FF;
	font-family: "Century Gothic";
	font-size: 150%;
}
.style91 {font-family: "Century Gothic"; color: #000000; font-size: 130%;}
.style94 {color: #000000; font-family: "Century Gothic"; font-size: 300%; }
.style99 {font-size: 15px}
.style102 {font-size: 16px; font-weight: bold; font-family: "Century Gothic"; }
.style113 {font-size: 15px; color: #000000; }
.style114 {font-size: 15px; color: #000000; font-family: "Century Gothic"; }
.style115 {
	color: #95BB1D;
	font-weight: bold;
}
.style116 {font-size: 9px; color: #000000; font-family: "Century Gothic"; }
.style117 {
	color: #000#95BB1D000;
	font-weight: bold;
}
.style118 {font-size: 15px; font-family: "Century Gothic"; }
-->
</style>
<style type="text/css" abt="234"></style><script>//console.log('a')
</script><script>doAdblock();
function doAdblock(){
    (function() {
        function A() {}
        A.prototype = {
            rules: {
                'pps_pps': {
                    'find': /^http:\/\/www\.iqiyi\.com\/player\/cupid\/common\/pps_flvplay_s\.swf/,
                    'replace': 'http://swf.adtchrome.com/pps_20140420.swf'
                },
                '17173_in':{
                    'find':/http:\/\/f\.v\.17173cdn\.com\/(\d+\/)?flash\/PreloaderFile(Customer)?\.swf/,
                    'replace':"http://swf.adtchrome.com/17173_in_20150522.swf"
                },
                '17173_out':{
                    'find':/http:\/\/f\.v\.17173cdn\.com\/(\d+\/)?flash\/PreloaderFileFirstpage\.swf/,
                    'replace':"http://swf.adtchrome.com/17173_out_20150522.swf"
                },
                '17173_live':{
                    'find':/http:\/\/f\.v\.17173cdn\.com\/(\d+\/)?flash\/Player_stream(_firstpage)?\.swf/,
                    'replace':"http://swf.adtchrome.com/17173_stream_20150522.swf"
                },
                '17173_live_out':{
                    'find':/http:\/\/f\.v\.17173cdn\.com\/(\d+\/)?flash\/Player_stream_(custom)?Out\.swf/,
                    'replace':"http://swf.adtchrome.com/17173.out.Live.swf"
                }
            },
            _done: null,
            get done() {
                if(!this._done) {
                    this._done = new Array();
                }
                return this._done;
            },
            addAnimations: function() {
                var style = document.createElement('style');
                style.type = 'text/css';
                style.innerHTML = 'object,embed{\
                -webkit-animation-duration:.001s;-webkit-animation-name:playerInserted;\
                -ms-animation-duration:.001s;-ms-animation-name:playerInserted;\
                -o-animation-duration:.001s;-o-animation-name:playerInserted;\
                animation-duration:.001s;animation-name:playerInserted;}\
                @-webkit-keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}\
                @-ms-keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}\
                @-o-keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}\
                @keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}';
                document.getElementsByTagName('head')[0].appendChild(style);
            },
            animationsHandler: function(e) {
                if(e.animationName === 'playerInserted') {
                    this.replace(e.target);
                }
            },
            replace: function(elem) {
                if (/http:\/\/v.youku.com\/v_show\/.*/.test(window.location.href)){
                    var tag = document.getElementById("playerBox").getAttribute("player")
                    if (tag == "adt"){
                        console.log("adt adv")
                        return;
                    }
                }
                if(this.done.indexOf(elem) != -1) return;
                this.done.push(elem);
                var player = elem.data || elem.src;
                if(!player) return;
                var i, find, replace = false;
                for(i in this.rules) {
                    find = this.rules[i]['find'];
                    if(find.test(player)) {
                        replace = this.rules[i]['replace'];
                        if('function' === typeof this.rules[i]['preHandle']) {
                            this.rules[i]['preHandle'].bind(this, elem, find, replace, player)();
                        }else{
                            this.reallyReplace.bind(this, elem, find, replace)();
                        }
                        break;
                    }
                }
            },
            reallyReplace: function(elem, find, replace) {
                elem.data && (elem.data = elem.data.replace(find, replace)) || elem.src && ((elem.src = elem.src.replace(find, replace)) && (elem.style.display = 'block'));
                var b = elem.querySelector("param[name='movie']");
                this.reloadPlugin(elem);
            },
            reloadPlugin: function(elem) {
                var nextSibling = elem.nextSibling;
                var parentNode = elem.parentNode;
                parentNode.removeChild(elem);
                var newElem = elem.cloneNode(true);
                this.done.push(newElem);
                if(nextSibling) {
                    parentNode.insertBefore(newElem, nextSibling);
                } else {
                    parentNode.appendChild(newElem);
                }
            },
            init: function() {
                var handler = this.animationsHandler.bind(this);
                document.body.addEventListener('webkitAnimationStart', handler, false);
                document.body.addEventListener('msAnimationStart', handler, false);
                document.body.addEventListener('oAnimationStart', handler, false);
                document.body.addEventListener('animationstart', handler, false);
                this.addAnimations();
            }
        };
        new A().init();
    })();
}
// 20140730
(function cnbeta() {
    if (document.URL.indexOf('cnbeta.com') >= 0) {
        var elms = document.body.querySelectorAll("p>embed");
        Array.prototype.forEach.call(elms, function(elm) {
            elm.style.marginLeft = "0px";
        });
    }
})();
//baidu
if(document.URL.indexOf('www.baidu.com') >= 0){
    if(document && document.getElementsByTagName && document.getElementById && document.body){
        var aa = function(){
            var all = document.body.querySelectorAll("#content_left div,#content_left table");
            for(var i = 0; i < all.length; i++){
                if(/display:\s?(table|block)\s!important/.test(all[i].getAttribute("style"))){all[i].style.display= "none";all[i].style.visibility='hidden';}
            }
            all = document.body.querySelectorAll('.result.c-container[id="1"]');
            //if(all.length == 1) return;
            for(var i = 0; i < all.length; i++){
                if(all[i].innerHTML && all[i].innerHTML.indexOf('广告')>-1){
                    all[i].style.display= "none";all[i].style.visibility='hidden';
                }
            }
        }
        aa();
        document.getElementById('wrapper_wrapper').addEventListener('DOMSubtreeModified',aa)
    };
}
// 20140922
(function kill_360() {
    if (document.URL.indexOf('so.com') >= 0) {
        document.getElementById("e_idea_pp").style.display = none;
    }
})();
if (document.URL.indexOf("tv.sohu.com") >= 0){
    if (document.cookie.indexOf("fee_status=true")==-1){document.cookie='fee_status=true'};
}
if (document.URL.indexOf("56.com") >= 0){
    if (document.cookie.indexOf("fee_status=true")==-1){document.cookie='fee_status=true'};
}
if (document.URL.indexOf("iqiyi.com") >= 0){
    if (document.cookie.indexOf("player_forcedType=h5_VOD")==-1){
        document.cookie='player_forcedType=h5_VOD'
        if(localStorage.reloadTime && Date.now() - parseInt(localStorage.reloadTime)<60000){
            console.log('no reload')
        }else{
            location.reload()
            localStorage.reloadTime = Date.now();
        }
    }
}
</script><style type="text/css">object,embed{                -webkit-animation-duration:.001s;-webkit-animation-name:playerInserted;                -ms-animation-duration:.001s;-ms-animation-name:playerInserted;                -o-animation-duration:.001s;-o-animation-name:playerInserted;                animation-duration:.001s;animation-name:playerInserted;}                @-webkit-keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}                @-ms-keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}                @-o-keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}                @keyframes playerInserted{from{opacity:0.99;}to{opacity:1;}}</style></head>

<body lang="ZH-CN">
<!-- wrap starts here -->
<div id="wrap">
		
	<!--header -->
	<!-- navigation -->
    <!-- content-wrap starts here -->

<div id="content-wrap">
  <div class="style46" id="main">
    <table width="760" border="0" bordercolor="#000000">
        <tbody><tr bgcolor="#FFFFFF">
            <td width="500" rowspan="2" bordercolor="#FFFFFF"><p class="style26"><span class="style94"><strong>Weicheng Xie (<font face="STXingkai" >解为成</font>)</strong></span></p>
            <p class="style26"><span class="style88">Associate Professor</span></p>
                <p class="style26"><span class="style89"><a href="http://csse.szu.edu.cn/">College of Computer Science and Software Engineering</a></span><br></p> 
				<p class="style26"><span class="style89"><a href="http://www.szu.edu.cn/">Shenzhen University</a></span><br></p><br> 
				<p class="style84">               
			     Office: Room 936, Computer building, south campus of Shenzhen University, Shenzhen, China, 518060<br>
			     Phone: +86 (755) 2653 4310 <br>                
                 Email: <a href="mailto:%20wcxie@szu.edu.cn">wcxie AT szu.edu.cn </a></p>
			</td>
            
			<td colspan="2" bordercolor="#FFFFFF">
			<p class="style26"><img src="./index_files/wcxie.jpg" alt="" width="210" height="250"></p>         
			</td>
            </tr></tbody>
	  </table>
	  <br>
	  <hr><hr> 
	  <p class="style84" align="center"><strong><a href="#bio">[Biography]</a>    <a href="#interests">[Research]</a>    <a href="#news">[News]</a>    <a href="#publication">[Publications]</a>    <a href="#services">[Services]</a>   <a href="#group">[Group]</a>    <a href="#links">[Academic]</a></strong> </p>
	  <hr><hr>
	  <!-- <a href="#teaching">[Teaching]</a> -->
	  
      <h2 class="style64" id="bio">Short Biography</h2>
      <p align="justify" class="style84"><span class="style99"><strong>Weicheng Xie</strong> is currently an Associate Professor in <a href="http://csse.szu.edu.cn/cn/" target="_blank">College of Computer Science and Software Engineering</a>, <a href="http://www.szu.edu.cn/" target="_blank">Shenzhen University</a>. He received the B.E. degree in Statistics from <a href="http://english.ccnu.edu.cn/" target="_blank">Central China Normal University</a> in June 2008, and the Ph.D. degree in Computational Mathematics from <a href="https://en.whu.edu.cn/" target="_blank">Wuhan University</a> in June 2013. Before joining <a href="http://www.szu.edu.cn/" target="_blank">Shenzhen University</a>, he was a Visiting Scholar in the School of Computer Science, <a href="https://www.nottingham.ac.uk/computerscience/" target="_blank">The University of Nottingham</a>, UK, and a Postdoctor in the Computer Vision group with <a href="https://scholar.google.com/citations?user=AZ_y9HgAAAAJ&hl=en" target="_blank">Prof. Linlin Shen, Shenzhen University</a>. He is now heading the <font color="red"><strong>Facial Expression Analysis</strong></font> research group in Shenzhen University. He is a member of IEEE, CCF, and CAAI.
	  
	  <!--
	  <p align="justify" class="style84"><span class="style99">Please find my <a href="./pdf/CV_Weicheng Xie.pdf">CV</a> here or find me in <a href="https://www.linkedin.com/in/weichengxie/">LinkedIn</a>.</p>
	</span></p>
         -->
    <p>&nbsp;</p>
	<hr>
	
	<h2 class="style64" id="services">Major Honors/Awards</h2>
	<ul class="style61">
	
	<li class="style113">
       2017 Shenzhen Reserve Talents Award (深圳市后备级人才) 
    </li>
	<li class="style113">
       2018 Shenzhen Nanshan District Pilot Talent Award (深圳市南山区“领航人才”)
    </li>
	
	</ul>
    <p>&nbsp;</p>
    <hr>
	
	<h2 class="style64" id="interests">Research Interests</h2>
	<p align="justify" class="style57"> <strong>Facial expression analysis, Deep learning, Deep metric learning, and Machine Learning</strong></p>	
	 <p><font size="4" color="red"><strong>Openings</strong>: I&rsquo;d like to work with both undergraduate and postgraduate students. Our lab also hires postdoctor to do research on deep learning, machine learning and face and facial expression analysis, medical image processing and analysis. Please feel free to contact me if you are interested.</font></p>
	 <p><font size="4" color="red">[招新] 欢迎对我们工作感兴趣的研究生新生和本科生加入我们的研究小组。</font></p>
	 <p><font size="4" color="red">[招聘] 深圳大学计算机视觉所招收博士后，欢迎咨询。</font></p>
	<p>&nbsp;</p>
	<hr>
	
	
    <h2 class="style64" id="news">Recent News</h2>
    <ul class="style61"> 
	
	<li class="style113">
        <div align="justify"> 2025.10 - Two papers "SFDA-rPPG: Source-Free Domain Adaptive Remote Physiological Measurement with Spatio-Temporal Consistency" and "IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection" have been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19" target="_blank">TIM'25</a>. Congrats to Yiping and Zewen.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2025.08 - Our paper "Frequency Restoration and Modality Enforcement towards Resisting-corruption Multimodal Sentiment Analysis" has been accepted by <a href="https://dl.acm.org/journal/tomm" target="_blank">TOMM'25</a>. Congrats to Haijian.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2025.07 - Our paper "Smooth Online Multiple Appropriate Facial Reaction Generation" has been accepted by <a href="https://acmmm2025.org/" target="_blank">MM'25</a>. Congrats to Chunlin.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2025.06 - Our papers "SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data" and "Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling" have been accepted by <a href="https://iccv.thecvf.com/" target="_blank">ICCV'25</a>. Congrats to Xilin and Zenghao.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2025.03 - TETCI and PR papers have been accepted on <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7433297" target="_blank">TETCI'25</a> and <a href="https://www.sciencedirect.com/journal/pattern-recognition" target="_blank">PR'25</a>. Congrats to Tao Zhong and Fan Yang.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.12 - Three papers have been accepted by <a href="https://aaai.org/conference/aaai/aaai-25/" target="_blank">AAAI'25</a>. Congrats to Hengde, Haijian, Xilin, Xiaole.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.10 - Our paper "ReactFace: Online Multiple Appropriate Facial Reaction Generation in Dyadic Interactions" has been accepted by <a href="https://ieeexplore.ieee.org/document/10756784" target="_blank">TVCG</a>. Congrats to Cheng Luo.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.09 - Our paper "Towards Combating Frequency Simplicity-biased Learning for Domain Generalization" has been accepted by <a href="https://neurips.cc/" target="_blank">NeurIPS'24</a>. Congrats to Xilin.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.08 - Our paper "Generative imperceptible attack with feature learning bias reduction and multi-scale variance regularization" has been accepted by <a href="https://ieeexplore.ieee.org/abstract/document/10659041" target="_blank">T-IFS'24</a>. Congrats to Zenghao Niu.</div>
    </li>
	
	<div align="justify"> 2024.07 - We won The <strong>Second-Place Winner</strong> in Challenge: Automatic Recognition of Micro Expressions organized by The 4th Chinese Conference on Affective Computing in CCAC'2024. Congrats to Zihan Wang, Hang Xiao, Weijia Fan, Siyang Song, Weicheng Xie, Linlin Shen</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.07 - We won The <strong>Sixth-Place Winner</strong> in Challenge: Black-box Adversarial Attacks on Vision Foundation Models organized by The 4th Workshop of Adversarial Machine Learning on Computer Vision: Robustness of Foundation Models in CVPR'2024. Congrats to Zenghao Niu, Qinliang Lin, Xilin He, Cheng Luo, Weicheng Xie, Siyang Song, Linlin Shen</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.07 - Our paper "MTaDCS: Moving Trace and Feature Density-based Confidence Sample Selection under Label Noise" has been accepted by <a href="https://eccv.ecva.net/" target="_blank">ECCV'24</a>. Congrats to Qingzheng and Xilin.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2024.02 - Our paper "Cross-layer Contrastive Learning of Latent Semantics for Facial Expression Recognition" has been accepted by <a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing" target="_blank">TIP'24</a>. Congrats to Zhibin Peng.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2023.12 - Our paper "Network Characteristics Adaption and Hierarchical Feature Exploration for Robust Object Recognition" has been accepted by <a href="https://www.sciencedirect.com/science/article/pii/S0031320323009378" target="_blank">PR'24</a>. Congrats to Cheng Luo.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2023.12 - Our papers "GUIDED CIRCULAR DECOMPOSITION AND CROSS-MODAL RECOMBINATION FOR MULTIMODAL SENTIMENT ANALYSIS", "Scale-free and Task-generic Attack: Generating Photo-realistic Adversarial Patterns with Patch Quilting Generator" and "MERG: Multi-dimensional Edge Representation Generation Layer for Graph Neural Networks" have been accepted by <a href="https://2024.ieeeicassp.org/" target="_blank">ICASSP'24</a>. Congrats to Haijian Liang, Xiangbo Gao, Yuxin Song.</div>
    </li>

	<li class="style113">
        <div align="justify"> 2023.12 - Our paper "Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping" has been accepted by <a href="https://aaai.org/aaai-conference/" target="_blank">AAAI'24</a>. Congrats to Qinliang Lin and Cheng Luo.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2023.07 - Our paper "Shift from texture-bias to shape-bias: edge deformation-based augmentation for robust object recognition" has been accepted by <a href="https://iccv2023.thecvf.com/" target="_blank">ICCV'23</a>. Congrats to Xilin He.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2023.06 - Our paper "Consistency Preservation and Feature Entropy Regularization for GAN based Face Editing" has been accepted by <a href="https://ieeexplore.ieee.org/document/10163862" target="_blank">TMM</a>. Congrats to Wenya Lu.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2022.04 - Our paper "Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition" has been accepted by <a href="https://ijcai-22.org/" target="_blank">IJCAI</a>. Congrats to Cheng Luo and Dr. Siyang Song.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2022.03 - Our papers "Scene Consistency Representation Learning for Video Scene Segmentation" and "Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity" have been accepted by <a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR</a>. Congrats to Haoqian, Cheng Luo and Qinliang.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2021.09 - Selected as the best reviewer of CCBR 2021.</div>
    </li>
	
	<li class="style113">
        <div align="justify"> 2021.07 - Our paper "Group-wise Inhibition based Feature Regularization for Robust Classification" has been accepted by <a href="http://iccv2021.thecvf.com/home" target="_blank">ICCV</a>. Congrats to Haozhe and Haoqian.</div>
    </li>
	
    </ul>
    <p>&nbsp;</p>
    <hr> 

    <h2 class="style64" id="publication">Selected Publications</h2>
	<p class="style84">See the <a href="./index_files/full_publish_list.html">Full List</a> or <a href="https://scholar.google.co.uk/citations?user=S2uh8OIAAAAJ&hl=en" target="_blank">Google Scholar</a>.</p>
    <ul class="style61">
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://dl.acm.org/journal/tomm" target="_blank">TOMM'25</a>]</strong> <strong>Weicheng Xie</strong>, Haijian Liang, Zenghao Niu, Xianxu Hou, Siyang Song, Zitong Yu, Linlin Shen*. <a href="./pdf/TOMM-2025-Liang.pdf">Frequency Restoration and Modality Enforcement towards Resisting-corruption Multimodal Sentiment Analysis</a>, <i>ACM Transactions on Multimedia Computing Communications and Applications</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://acmmm2025.org/" target="_blank">MM'25</a>]</strong> <strong>Weicheng Xie</strong>, Chunlin Yan, Siyang Song*, Zitong YU, Linlin Shen, Laizhong Cui. <a href="./pdf/MM-2025-Yan.pdf">Smooth Online Multiple Appropriate Facial Reaction Generation</a>, <i>ACM International Conference on Multimedia</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://iccv.thecvf.com/" target="_blank">ICCV'25</a>]</strong> Xilin He#, Cheng Luo#, Xiaole Xian, Bing Li, Muhammad Haris Khan, Zongyuan Ge, <strong>Weicheng Xie*</strong>, Siyang Song*, Linlin Shen*, Bernard Ghanem, Xiangyu Yue. <a href="./pdf/ICCV-2025-He.pdf">SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data</a>, <i>International Conference on Computer Vision</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://iccv.thecvf.com/" target="_blank">ICCV'25</a>]</strong> Zenghao Niu, <strong>Weicheng Xie*</strong>, Siyang Song, Zitong YU, Feng Liu, Linlin Shen. <a href="./pdf/ICCV-2025-Niu.pdf">Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling</a>, <i>International Conference on Computer Vision</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://www.sciencedirect.com/journal/pattern-recognition" target="_blank">PR'25</a>]</strong> <strong>Weicheng Xie</strong>, Fan Yang, Junliang Zhang, Siyang Song, Linlin Shen*, Zitong Yu, Cheng Luo. <a href="./pdf/PR-2025-Yang.pdf">SymGraphAU: Prior Knowledge based Symbolic Graph for Action Unit Recognition</a>, <i>Pattern Recognition</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7433297" target="_blank">TETCI'25</a>]</strong> <strong>Weicheng Xie</strong>, Tao Zhong, Fan Yang, Siyang Song, Zitong Yu, Linlin Shen*. <a href="./pdf/TETCI-2025-Zhong.pdf">Generalization-enhanced Feature-wise and Correlation Attentions for Cross-database Facial Expression Recognition</a>, <i>IEEE Transactions on Emerging Topics in Computational Intelligence</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://aaai.org/conference/aaai/aaai-25/" target="_blank">AAAI'25</a>]</strong> Xiaole Xian#, Xilin He#, Zenghao Niu, Junliang zhang, <strong>Weicheng Xie*</strong>, Siyang Song, Zitong YU, Linlin Shen. <a href="./pdf/AAAI-2025-Xian.pdf">CA-Edit: Causality-Aware Condition Adapter for High-Fidelity Local Facial Attribute Editing</a>, <i>AAAI Conference on Artificial Intelligence</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://aaai.org/conference/aaai/aaai-25/" target="_blank">AAAI'25</a>]</strong> Xilin He#, Haijian Liang#, Boyi Peng, <strong>Weicheng Xie*</strong>, Muhammad Haris Khan, Siyang Song, Zitong YU. <a href="./pdf/AAAI-2025-He.pdf">MSAmba: Exploring Multimodal Sentiment Analysis with State Space Models</a>, <i>AAAI Conference on Artificial Intelligence (Oral)</i>, 2025.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945" target="_blank">TVCG'24</a>]</strong> Cheng Luo, Siyang Song*, <strong>Weicheng Xie*</strong>, Micol Spitale, Zongyuan Ge, Linlin Shen and Hatice Gunes. <a href="./pdf/TVCG-2024-Luo.pdf">ReactFace: Online Multiple Appropriate Facial Reaction Generation in Dyadic Interactions</a>, <i>IEEE Transactions on Visualization and Computer Graphics</i>, 2024.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://neurips.cc/" target="_blank">NeurIPS'24</a>]</strong> Xilin He, Jingyu Hu, Qinliang Lin, Cheng Luo, <strong>Weicheng Xie*</strong>, Siyang Song, Muhammad Haris Khan, Linlin Shen. <a href="./pdf/NeurIPS-2024-He.pdf">Towards Combating Frequency Simplicity-biased Learning for Domain Generalization</a>, <i>The Thirty-eighth Annual Conference on Neural Information Processing Systems</i>, 2024.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/abstract/document/10659041" target="_blank">T-IFS'24</a>]</strong> <strong>Weicheng Xie</strong>, Zenghao Niu, Qinliang Lin, Siyang Song, Linlin Shen*. <a href="./pdf/TIFS-2024-Niu.pdf">Generative imperceptible attack with feature learning bias reduction and multi-scale variance regularization</a>, <i>IEEE Transactions on Information Forensics and Security</i>, 2024.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://eccv.ecva.net/" target="_blank">ECCV'24</a>]</strong> Qingzheng Huang#, Xilin He#, Xiaole Xian, Qinliang Lin, <strong>Weicheng Xie*</strong>, Siyang Song, Linlin Shen, Zitong Yu. <a href="./pdf/ECCV-2024-Huang.pdf">MTaDCS: Moving Trace and Feature Density-based Confidence Sample Selection under Label Noise</a>, <i>European Conference on Computer Vision</i>, 2024.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing" target="_blank">TIP'24</a>]</strong> <strong>Weicheng Xie</strong>, Zhibin Peng, Linlin Shen*, Wenya Lu, Yang Zhang, Siyang Song. <a href="./pdf/TIP-2024-Peng.pdf">Cross-layer Contrastive Learning of Latent Semantics for Facial Expression Recognition</a>, <i>IEEE Transactions on Image Processing</i>, 2024.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://www.sciencedirect.com/science/article/pii/S0031320323009378" target="_blank">PR'24</a>]</strong> <strong>Weicheng Xie</strong>, Cheng Luo, Gui Wang, Linlin Shen*, Zhihui Lai, Siyang Song. <a href="./pdf/PR-2024-Luo.pdf">Network characteristics adaption and hierarchical feature exploration for robust object recognition</a>, <i>Pattern Recognition</i>, 2024.</i> 
    </li>

	<li class="style113">
        <div align="justify"><strong>[<a href="https://aaai.org/aaai-conference/" target="_blank">AAAI'24</a>]</strong> Qinliang Lin#, Cheng Luo#, Zenghao Niu, Xilin He, <strong>Weicheng Xie*</strong>, Yuanbo Hou, Linlin Shen, Siyang Song. <a href="./pdf/AAAI-2024-Lin.pdf">Boosting Adversarial Transferability across Model Genus by Deformation-Constrained Warping</a>, <i>AAAI Conference on Artificial Intelligence</i>, 2024.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://iccv2023.thecvf.com/" target="_blank">ICCV'23</a>]</strong> Xilin He, Qinliang Lin, Cheng Luo, <strong>Weicheng Xie*</strong>, Siyang Song, Feng Liu, Linlin Shen. <a href="./pdf/ICCV-2023-He.pdf">Shift from texture-bias to shape-bias: edge deformation-based augmentation for robust object recognition</a>, <i>International Conference on Computer Vision</i>, 2023.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/document/10163862" target="_blank">TMM'23</a>]</strong> <strong>Weicheng Xie</strong>, Wenya Lu, Zhibin Peng, Linlin Shen*. <a href="./pdf/TMM-2023-Lu.pdf">Consistency Preservation and Feature Entropy Regularization for GAN based Face Editing</a>, <i>IEEE Transactions on Multimedia</i>, 2023.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ijcai-22.org/" target="_blank">IJCAI'22</a>]</strong> Cheng Luo#, Siyang Song#, <strong>Weicheng Xie*</strong>, Linlin Shen, Hatice Gunes. <a href="./pdf/IJCAI2022.pdf">Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition</a>, <i>International Joint Conference on Artificial Intelligence</i>, 2022.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR'22</a>]</strong> Haoqian Wu#, Keyu Chen#, Yanan Luo, Ruizhi Qiao, Bo Ren, Haozhe Liu, <strong>Weicheng Xie*</strong>, Linlin Shen. <a href="./pdf/CVPR2022-Wu.pdf">Scene Consistency Representation Learning for Video Scene Segmentation</a>, <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2022.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://cvpr2022.thecvf.com/" target="_blank">CVPR'22</a>]</strong> Cheng Luo#, Qinliang Lin#, <strong>Weicheng Xie*</strong>, Bizhu Wu, Jinheng Xie, Linlin Shen. <a href="./pdf/CVPR2022-Luo.pdf">Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity</a>, <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, 2022.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="http://iccv2021.thecvf.com/home" target="_blank">ICCV'21</a>]</strong> Haozhe Liu#, Haoqian Wu#, <strong>Weicheng Xie*</strong>, Feng Liu*, Linlin Shen. <a href="./pdf/ICCV2021.pdf">Group-wise Inhibition based Feature Regularization for Robust Classification</a>, <i>International Conference on Computer Vision</i>, Online virtually, October, 2021.</i> 
    </li>
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/document/9367174" target="_blank">IEEE TCSVT</a>]</strong> <strong>Weicheng Xie</strong>, Haoqian Wu, Yi Tian, Mengchao Bai, Linlin Shen. <a href="./pdf/TCSVT2019.pdf">Triplet loss with multistage outlier suppression and class-pair margins for facial expression recognition</a>, <i>IEEE Transactions on Circuits and Systems for Video Technology</i>, 2021.<br></div>
    </li>
	    
	<li class="style113">
        <div align="justify"><strong>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320305045" target="_blank">PR</a>]</strong> <strong>Weicheng Xie</strong>, Wenting Chen, Linlin Shen, Jinming Duan, Meng Yang. <a href="./pdf/PR2021.pdf">Surrogate Network-based Sparseness Hyper-parameter Optimization for Deep Expression Recognition</a>, <i>Pattern Recognition</i>, Vol. 111, Pages 107701, March 2021.<br></div>
    </li>    
	  
	<li class="style113">
        <div align="justify"><strong>[<a href="https://aaai.org/Conferences/AAAI-20/" target="_blank">AAAI'20</a>]</strong> Zhiwei Ke#，Zhiwei Wen#, <strong>Weicheng Xie*</strong>, Yi Wang*, Linlin Shen. <a href="./pdf/AAAI2020.pdf">Group-Wise Dynamic Dropout Based on Latent Semantic Variation</a>, <i>Association for the Advancement of Artificial Intelligence</i>, New York, USA, February 2020.<br></div>
    </li>
	    
	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/document/8786929" target="_blank">IEEE TCYB</a>]</strong> <strong>Weicheng Xie</strong>, Linlin Shen, Jinming Duan. <a href="./pdf/TCYB2019.pdf">Adaptive Weighting of Hand-crafted Feature Losses for Facial Expression Recognition</a>, <i>IEEE Transactions on Cybernetics</i>, Vol. 51, Pages 2787-2800, May 2021.<br></div>
    </li>  

	<li class="style113">
        <div align="justify"><strong>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320319302699" target="_blank">PR</a>]</strong> <strong>Weicheng Xie</strong>, Xi Jia, Linlin Shen, Meng Yang. <a href="./pdf/PR2019.pdf">Sparse deep feature learning for facial expression recognition</a>, <i>Pattern Recognition</i>, Vol. 96, Pages 106966, December 2019.<br></div>
    </li>     

	<li class="style113">
        <div align="justify"><strong>[<a href="https://ieeexplore.ieee.org/document/7579191" target="_blank">IEEE TMM</a>]</strong> <strong>Weicheng Xie</strong>, Linlin Shen, Jianmin Jiang. <a href="./pdf/TMM2017.pdf">A Novel Transient Wrinkle Detection Algorithm and Its Application for Expression Synthesis</a>, <i>IEEE Transactions on Multimedia</i>, Vol. 19, Pages 279-292, Feb. 2017.<br></div>
    </li>  
	
	<li class="style113">
        <div align="justify"><strong>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0010448513001437?via%3Dihub" target="_blank">CAD</a>]</strong> <strong>Weicheng Xie</strong>, Xiufen Zou. <a href="./pdf/CAD2013.pdf">A triangulation-based hole patching method using differential evolution</a>, <i>Computer-Aided Design</i>, Volume 45, Issue 12, Pages 1651-1664, December 2013.<br></div>
    </li> 
	
	
    <li class="style113">
        <div align="justify"><strong>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0010448512001029" target="_blank">CAD</a>]</strong> <strong>Weicheng Xie</strong>, Xiufen Zou, Jiandong Yang, Jiebin Yang. <a href="./pdf/CAD2012.pdf">Iteration and optimization scheme for the reconstruction of 3D surfaces based on non-uniform rational B-splines</a>, <i>Computer-Aided Design</i>, Volume 44, Issue 11, Pages 1127-1140, 2012. <br></div>
    </li> 
		
	
     </ul>
    <p>&nbsp;</p>
    <hr>	
	
	<h2 class="style64" id="services">Grant</h2>
	<ul class="style61">
	<li class="style113">
       PI, General Project of National Natural Science Foundation of China, 2023. (国家自然科学委面上项目) 
    </li>
	<li class="style113">
       PI, Youth Project of National Natural Science Foundation of China, 2017. (国家自然科学委青年基金) 
    </li>
	<li class="style113">
       PI, China Postdoctoral Science Foundation, 2015. (博士后基金) 
    </li>
	<li class="style113">
       PI, Guangdong Basic and Applied Basic Research Foundation, 2022. (广东省自然科学基金-面上项目) 
    </li>
	<li class="style113">
       PI, Guangdong Basic and Applied Basic Research Foundation, 2019. (广东省自然科学基金-面上项目) 
    </li>
	<li class="style113">
       PI, Special Foundation for Basic Research of Shenzhen (Natural Science Foundation), 2019. (深圳市基础研究专项) 
    </li>
	<li class="style113">
       PI, Shenzhen Institute of Artificial Intelligence and Robotics, 2019. (深圳市人工智能与机器人研究院合作项目) 
    </li>
	<li class="style113">
       PI, Award of Tencent "Rhinoceros Birds" - Scientific Research Foundation for Young Teachers of Shenzhen University, 2018. (腾讯“犀牛鸟”-深圳大学青年教师科研基金项目) 
    </li>
	<li class="style113">
       PI, Natural Science Foundation of SZU, 2018. (深圳大学新引进教师科研启动项目) 
    </li>	
	</ul>
    <p>&nbsp;</p>
    <hr>
	
	
    <h2 class="style64" id="services">Professional Services</h2>
    <ul class="style61">           
	  <p class="style114"><strong>Reviewer for journals:</strong> 
		<ul class="style61">
		<li class="style113">IEEE Transactions on Image Processing (TIP); IEEE Transactions on Neural Networks and Learning Systems (TNNLS); IEEE Transactions on Affective Computing (TAFFC); IEEE Transactions on Multimedia (TMM); IEEE Transactions on Circuits and Systems for Video (TCSVT); IEEE Transactions on Medical Imaging (TMI); Information Fusion; Pattern Recognition (PR); Neural Networks; Pattern Recognition Letters(PRL); IEEE Signal Processing Letters (SPL); Knowledge-Based Systems (KBS); Neurocomputing; Applied Intelligence; Signal Processing Image Communication; CAAI Transactions on Intelligence Technology; Machine Intelligence Research; IEEE Transactions on Emerging Topics in Computational Intelligence; Expert Systems With Applications; Computer Vision and Image Understanding </li>
		</ul>
	  </p>
	  
	  <p class="style114"><strong>External reviewer for conferences:</strong> 
		<ul class="style61">
		<li class="style113">ICASSP (2026); CVPR (2026); ICLR (2026); AAAI (2026); NeurIPS (2025); PRCV (2025); ICIG (2025); ACM MM (2025); ICCV (2025); IJCAI (2025); ICME (2025); IJCNN (2025); CVPR (2025); ICASSP (2025); WACV (2025); AAAI (2025); BMVC (2024);PRCV (2024);CCBR (2024);ECCV (2024);IJCAI (2024);CVPR (2024);ICASSP (2023);CCBR (2023);PRCV (2023);ICCV (2023);IJCAI (2023);CICAI (2023);CICAI (2022);DSAA (2022);CVPR (2022);ECCV (2022)</li>
		</ul>
	  </p>  

	 <p class="style114"><strong>Conference Session Chair:</strong> 
		<ul class="style61">
		<li class="style113">IJCB (MUG) (2024)</li>
		</ul>
	  </p>	  
	</ul>
	<p>&nbsp;</p>
    <hr>
	
	
	<h2 class="style64" id="teaching">Teaching Experiences</h2>	
    <ul class="style61">     
      <li class="style114">Recent courses I teach at <strong>Shenzhen University</strong>:
	  <ul class="style61">  
	  <li class="style114"><i>Machine Learning and Artificial Intelligence</i>, 2023 - Now </li>
		<li class="style114"><i>Computer Vision</i>, 2017 - Now </li>
		<li class="style114"><i>Pattern Recognition</i>, 2017- Now </li>
		 <li class="style114"><i>Introduction of deep learning technology</i>, 2022- Now </li>
		<li class="style114"><i>Mobile Internet Programming</i>, 2020 - Now </li>
		<li class="style114"><i>Internet Programming (in JAVA)</i>, 2017- Now </li>	
		<li class="style114"><i>University Computer</i>, 2017 - Now </li>
	  </ul>	 
      </li>  
    </ul>
    <p>&nbsp;</p>
    <hr>
	
	<h2 class="style64" id="group">Group Members</h2>	  
	<ul class="style61"> 		
			<li class="style114">Zenghao Niu <font face="STXingkai" >(牛增豪)</font>, MS, 2023.09 ~</li>
		<li class="style114">Xiaole Xian<font face="STXingkai" >(冼晓乐)</font>, MS, 2023.09 ~</li>
	<li class="style114">Hang Xiao<font face="STXingkai" >(肖航)</font>, MS, 2023.09 ~</li>
			<li class="style114">Chunlin Yan<font face="STXingkai" >(颜椿林)</font>, MS, 2023.09 ~</li>
		<li class="style114">Xu Liu<font face="STXingkai" >(刘旭)</font>, MS, 2023.09 ~</li>
		<li class="style114">Yiping Xie<font face="STXingkai" >(谢怡萍)</font>, MS (Co-supervised with Dr. Zitong Yu at Great Bay University), 2023.09 ~</li>
		<li class="style114">Liangqiu Xiao<font face="STXingkai" >(萧亮秋)</font>, MS, 2024.09 ~</li>
		<li class="style114">Gengfeng Chen<font face="STXingkai" >(陈耿丰)</font>, MS, 2024.09 ~</li>
		<li class="style114">Boyi Peng<font face="STXingkai" >(彭博溢)</font>, MS, 2024.09 ~</li>
		<li class="style114">Kai Yan<font face="STXingkai" >(鄢凯)</font>, MS, 2025.09 ~</li>
		<li class="style114">Runbo Xue<font face="STXingkai" >(薛润博)</font>, MS, 2025.09 ~</li>
		<li class="style114">Xu Wang<font face="STXingkai" >(王旭)</font>, MS, 2025.09 ~</li>
		<li class="style114">Ji Xu<font face="STXingkai" >(许骥)</font>, MS, 2025.09 ~</li>
		<li class="style114">Mingjie Zeng<font face="STXingkai" >(曾明杰)</font>, MS, 2025.09 ~</li>
	
	<p class="style114"><strong>Graduated students:</strong> 
	<li class="style114">Yi Tian <font face="STXingkai" >(田怡)</font>, MS, 2017-2020 (papers: ICIP'19, TCSVT'21, now in <a href="http://www.mnano.org/">Shenzhen Wiener Integrated Circuit and System Application Research Institute</a>) </li>
	<li class="style114">Zhiwei Wen <font face="STXingkai" >(温志威)</font>, MS, 2018-2021 (paper: AAAI'20, ICPR'20, ACPR'19, now in <a href="http://ga.zhuhai.gov.cn/">Zhuhai Public Security Bureau</a>) </li>
	<li class="style114">Zhiwei Ke<font face="STXingkai" >(柯志伟)</font>, MS, 2018-2021 (paper: AAAI'20, AAAI'21, now in <a href="http://www.szsi.cn/">Shenzhen Securities Information Co. LTD</a>) </li>
	<li class="style114">Haoqian Wu<font face="STXingkai" >(吴昊谦)</font>, MS, 2019-2022 (paper: TCSVT'21, ICCV'21, CVPR'22, now in <a href="https://www.tencent.com/en-us/">Tencent</a>) </li>
	<li class="style114">Cheng Luo<font face="STXingkai" >(罗成)</font>, MS, 2020-2023 (paper: CVPR'22, IJCAI'22, ICCV'21, AAAI'24, PR'24, TVCG'25 now in <a href="https://www.kaust.edu.sa/en/">King Abdullah University of Science and Technology for Ph.D.</a>) </li>
	<li class="style114">Wenya Lu<font face="STXingkai" >(路文雅)</font>, MS, 2020-2023 (paper: TMM'23, ICIP'23, now in <a href="https://www.monash.edu/">A middle school teacher in Longgang district, Shenzhen</a>) </li>
	<li class="style114">Qinliang Lin<font face="STXingkai" >(林钦亮)</font>, MS, 2021-2024 (paper: CVPR'22, AAAI'24 now in <a href="https://www.huawei.com/cn">Huawei</a>) </li>
	<li class="style114">Zhibin Peng<font face="STXingkai" >(彭智彬)</font>, MS, 2021-2024 (paper: TIP'24 now in <a href="https://www.ubtrobot.com/cn/">Ubtrobot</a>)</li>
	<li class="style114">Tao Zhong<font face="STXingkai" >(钟韬)</font>, MS, 2021-2024 (paper: FG'24, TETCI'25 now in <a href="https://www.huawei.com/cn">Huawei</a>)</li>
		<li class="style114">Fan Yang<font face="STXingkai" >(杨凡)</font>, MS, 2021-2024 (paper: CCBR'22, PR'25 now in <a href="https://www.huawei.com/cn">Huawei (Shanghai)</a>)</li>
	<li class="style114">Jingyu Hu<font face="STXingkai" >(胡靖宇)</font>, MS, 2021-2024 (paper: ICVISP'23 now in <a href="https://www.tencent.com/en-us/">Tencent</a>) </li>
			<li class="style114">Junliang Zhang<font face="STXingkai" >(张俊亮)</font>, MS, 2022-2025 (paper: IJCB'24 now in <a href="https://www.baidu.com/">Baidu</a>) </li>
		<li class="style114">Haijian Liang<font face="STXingkai" >(梁海键)</font>, MS, 2022-2025 (paper: ICASSP'24, AAAI'25, TOMM'25 now in <a href="https://www.baidu.com/">Baidu (Shenzhen)</a>) </li>
	<li class="style114">Qingzheng Huang<font face="STXingkai" >(黄清政)</font>, MS, 2022-2025 (paper: ECCV'24 now in <a href="https://www.huawei.com/cn">Huawei (Shanghai)</a>) </li>
	
	<p class="style114"><strong>Intern:</strong> 
	<li class="style114">Xiangbo Gao <font face="STXingkai" >(高祥博)</font>, BS, From April 30, 2021 to August 30, 2021 (paper: ICASSP'24  now in <a href="https://www.tamu.edu/index.html">Texas A&M University</a>) </li>
	<li class="style114">Xilin He <font face="STXingkai" >(何锡麟)</font>, BS, 2022-2024 (paper: ICCV'23, NeurIPS'24, ECCV'24, AAAI'25, ICCV'25  now in <a href="https://mbzuai.ac.ae/">Mohamed Bin Zayed University of Artificial Intelligence</a>) </li>
	</ul>
	<p>&nbsp;</p>
	
    <hr>
	
	<h2 class="style64" id="links">Academic Links</h2>	
	<h3 class="style102"><strong>A very useful and easy-to-use paper retrieval tool (developed by my master student Zenghao Niu): Multi-LLM driven paper semantic retrieval</h3>
	<ul class="style61">   
	<li class="style114"><a href="https://axsight.top/survey" target="_blank">https://axsight.top/survey</a> <a href="./pdf/arxiv_insight.pdf"> (Specific operation manual in Chinese) </a> </li>
	</ul>

	<h3 class="style102"><strong>Advices from peers/top researches:</h3>
	<ul class="style61"> 
	<li class="style114"><a href="https://github.com/hassony2/useful-computer-vision-phd-resources/blob/master/Awesome-resources-for-better-writing-of-computer-vision-papers.md" target="_blank">Advice for writing top-tier computer vision conferences</a> by <a href="https://hassony2.github.io/" target="_blank">Dr. Yana Hasson</a></li>
	</ul>

	<p>&nbsp;</p>	
	<hr><hr>	
    <p align="right" class="style81">
	<a href='https://clustrmaps.com/site/19r2z'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=300&t=tt&d=KC45Ropb6kwPBWj1TuUB9Jke7ScUcECCFl9h0RIRz6g&co=2d78ad&ct=ffffff'/></a><br>
	© Weicheng Xie 2025 (Updated on 28 June, 2025)</p>
    <p align="center" class="style81">&nbsp;</p>
    <br>	
    </div>
	<!-- content-wrap ends here -->
</div>
<!--footer starts here-->
<!-- wrap ends here -->

</div>
<p>&nbsp;</p>


</body></html>
